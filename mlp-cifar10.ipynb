{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 318,410\n",
      "Trainable params: 318,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/80\n",
      "40000/40000 [==============================] - 2s 52us/step - loss: 2.0731 - acc: 0.2467 - val_loss: 1.9241 - val_acc: 0.3300\n",
      "Epoch 2/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.8849 - acc: 0.3320 - val_loss: 1.8196 - val_acc: 0.3682\n",
      "Epoch 3/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8188 - acc: 0.3646 - val_loss: 1.7748 - val_acc: 0.3795\n",
      "Epoch 4/80\n",
      "40000/40000 [==============================] - 1s 29us/step - loss: 1.7790 - acc: 0.3791 - val_loss: 1.7421 - val_acc: 0.3942\n",
      "Epoch 5/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.7535 - acc: 0.3885 - val_loss: 1.7248 - val_acc: 0.4013\n",
      "Epoch 6/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.7205 - acc: 0.4035 - val_loss: 1.7182 - val_acc: 0.4089\n",
      "Epoch 7/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.7071 - acc: 0.4075 - val_loss: 1.6904 - val_acc: 0.4202\n",
      "Epoch 8/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.6946 - acc: 0.4162 - val_loss: 1.6918 - val_acc: 0.4160\n",
      "Epoch 9/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.6785 - acc: 0.4201 - val_loss: 1.6691 - val_acc: 0.4241\n",
      "Epoch 10/80\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.6665 - acc: 0.4290 - val_loss: 1.6615 - val_acc: 0.4246\n",
      "Epoch 11/80\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.6531 - acc: 0.4318 - val_loss: 1.6399 - val_acc: 0.4421\n",
      "Epoch 12/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.6384 - acc: 0.4373 - val_loss: 1.6282 - val_acc: 0.4483\n",
      "Epoch 13/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.6279 - acc: 0.4422 - val_loss: 1.6204 - val_acc: 0.4488\n",
      "Epoch 14/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.6300 - acc: 0.4424 - val_loss: 1.6054 - val_acc: 0.4564\n",
      "Epoch 15/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.6152 - acc: 0.4473 - val_loss: 1.6228 - val_acc: 0.4518\n",
      "Epoch 16/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.6063 - acc: 0.4516 - val_loss: 1.6114 - val_acc: 0.4522\n",
      "Epoch 17/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.6011 - acc: 0.4525 - val_loss: 1.6040 - val_acc: 0.4573\n",
      "Epoch 18/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.6018 - acc: 0.4537 - val_loss: 1.6007 - val_acc: 0.4572\n",
      "Epoch 19/80\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.5820 - acc: 0.4644 - val_loss: 1.6020 - val_acc: 0.4629\n",
      "Epoch 20/80\n",
      "40000/40000 [==============================] - 1s 29us/step - loss: 1.5845 - acc: 0.4634 - val_loss: 1.6012 - val_acc: 0.4607\n",
      "Epoch 21/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.5749 - acc: 0.4654 - val_loss: 1.6181 - val_acc: 0.4622\n",
      "Epoch 22/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.5771 - acc: 0.4666 - val_loss: 1.5865 - val_acc: 0.4657\n",
      "Epoch 23/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.5661 - acc: 0.4710 - val_loss: 1.5789 - val_acc: 0.4695\n",
      "Epoch 24/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.5647 - acc: 0.4709 - val_loss: 1.6359 - val_acc: 0.4530\n",
      "Epoch 25/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.5600 - acc: 0.4764 - val_loss: 1.5647 - val_acc: 0.4771\n",
      "Epoch 26/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.5540 - acc: 0.4765 - val_loss: 1.5881 - val_acc: 0.4677\n",
      "Epoch 27/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.5520 - acc: 0.4766 - val_loss: 1.6000 - val_acc: 0.4627\n",
      "Epoch 28/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.5482 - acc: 0.4784 - val_loss: 1.5993 - val_acc: 0.4646\n",
      "Epoch 29/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.5522 - acc: 0.4776 - val_loss: 1.5633 - val_acc: 0.4758\n",
      "Epoch 30/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.5379 - acc: 0.4840 - val_loss: 1.5702 - val_acc: 0.4730\n",
      "Epoch 31/80\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.5365 - acc: 0.4857 - val_loss: 1.5713 - val_acc: 0.4741\n",
      "Epoch 32/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.5339 - acc: 0.4849 - val_loss: 1.5971 - val_acc: 0.4672\n",
      "Epoch 33/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.5318 - acc: 0.4853 - val_loss: 1.5731 - val_acc: 0.4757\n",
      "Epoch 34/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.5327 - acc: 0.4864 - val_loss: 1.5633 - val_acc: 0.4759\n",
      "Epoch 35/80\n",
      "40000/40000 [==============================] - 1s 29us/step - loss: 1.5308 - acc: 0.4896 - val_loss: 1.5680 - val_acc: 0.4797\n",
      "Epoch 36/80\n",
      "40000/40000 [==============================] - 1s 29us/step - loss: 1.5165 - acc: 0.4940 - val_loss: 1.5486 - val_acc: 0.4903\n",
      "Epoch 37/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.5255 - acc: 0.4900 - val_loss: 1.5594 - val_acc: 0.4877\n",
      "Epoch 38/80\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.5190 - acc: 0.4907 - val_loss: 1.5870 - val_acc: 0.4754\n",
      "Epoch 39/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.5100 - acc: 0.4956 - val_loss: 1.6050 - val_acc: 0.4777\n",
      "Epoch 40/80\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.5236 - acc: 0.4922 - val_loss: 1.5414 - val_acc: 0.4922\n",
      "Epoch 41/80\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.5122 - acc: 0.4982 - val_loss: 1.5657 - val_acc: 0.4776\n",
      "Epoch 42/80\n",
      "40000/40000 [==============================] - 1s 29us/step - loss: 1.5132 - acc: 0.4961 - val_loss: 1.5749 - val_acc: 0.4778\n",
      "Epoch 43/80\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.5070 - acc: 0.5014 - val_loss: 1.5611 - val_acc: 0.4860\n",
      "Epoch 44/80\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.5100 - acc: 0.5000 - val_loss: 1.5742 - val_acc: 0.4830\n",
      "Epoch 45/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.5056 - acc: 0.4998 - val_loss: 1.5766 - val_acc: 0.4822\n",
      "Epoch 46/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.5044 - acc: 0.5010 - val_loss: 1.5574 - val_acc: 0.4854\n",
      "Epoch 47/80\n",
      "40000/40000 [==============================] - 1s 29us/step - loss: 1.4999 - acc: 0.5033 - val_loss: 1.5495 - val_acc: 0.4907\n",
      "Epoch 48/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.5024 - acc: 0.5004 - val_loss: 1.5673 - val_acc: 0.4872\n",
      "Epoch 49/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.4931 - acc: 0.5023 - val_loss: 1.5602 - val_acc: 0.4883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.5012 - acc: 0.5032 - val_loss: 1.5330 - val_acc: 0.4957\n",
      "Epoch 51/80\n",
      "40000/40000 [==============================] - 1s 29us/step - loss: 1.4917 - acc: 0.5056 - val_loss: 1.5556 - val_acc: 0.4911\n",
      "Epoch 52/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.4939 - acc: 0.5041 - val_loss: 1.5431 - val_acc: 0.4945\n",
      "Epoch 53/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.4955 - acc: 0.5014 - val_loss: 1.5470 - val_acc: 0.4912\n",
      "Epoch 54/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.4840 - acc: 0.5080 - val_loss: 1.5459 - val_acc: 0.4994\n",
      "Epoch 55/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.4845 - acc: 0.5103 - val_loss: 1.5717 - val_acc: 0.4909\n",
      "Epoch 56/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.4881 - acc: 0.5080 - val_loss: 1.5525 - val_acc: 0.4898\n",
      "Epoch 57/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.4867 - acc: 0.5071 - val_loss: 1.5454 - val_acc: 0.4965\n",
      "Epoch 58/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.4845 - acc: 0.5093 - val_loss: 1.5289 - val_acc: 0.5021\n",
      "Epoch 59/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.4821 - acc: 0.5115 - val_loss: 1.5693 - val_acc: 0.4814\n",
      "Epoch 60/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.4774 - acc: 0.5116 - val_loss: 1.5382 - val_acc: 0.5059\n",
      "Epoch 61/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.4858 - acc: 0.5094 - val_loss: 1.5551 - val_acc: 0.4948\n",
      "Epoch 62/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.4808 - acc: 0.5122 - val_loss: 1.5742 - val_acc: 0.4848\n",
      "Epoch 63/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.4733 - acc: 0.5154 - val_loss: 1.5426 - val_acc: 0.5005\n",
      "Epoch 64/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.4863 - acc: 0.5123 - val_loss: 1.5528 - val_acc: 0.4908\n",
      "Epoch 65/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.4761 - acc: 0.5152 - val_loss: 1.5458 - val_acc: 0.4977\n",
      "Epoch 66/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.4668 - acc: 0.5184 - val_loss: 1.5727 - val_acc: 0.4869\n",
      "Epoch 67/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.4727 - acc: 0.5172 - val_loss: 1.5551 - val_acc: 0.4959\n",
      "Epoch 68/80\n",
      "40000/40000 [==============================] - 1s 29us/step - loss: 1.4722 - acc: 0.5194 - val_loss: 1.5692 - val_acc: 0.4924\n",
      "Epoch 69/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.4740 - acc: 0.5153 - val_loss: 1.5817 - val_acc: 0.4821\n",
      "Epoch 70/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.4688 - acc: 0.5154 - val_loss: 1.5357 - val_acc: 0.5016\n",
      "Epoch 71/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.4725 - acc: 0.5167 - val_loss: 1.5433 - val_acc: 0.4983\n",
      "Epoch 72/80\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.4640 - acc: 0.5206 - val_loss: 1.5669 - val_acc: 0.4908\n",
      "Epoch 73/80\n",
      "40000/40000 [==============================] - 1s 26us/step - loss: 1.4697 - acc: 0.5175 - val_loss: 1.5612 - val_acc: 0.4908\n",
      "Epoch 74/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.4651 - acc: 0.5195 - val_loss: 1.6018 - val_acc: 0.4791\n",
      "Epoch 75/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.4767 - acc: 0.5180 - val_loss: 1.5526 - val_acc: 0.5031\n",
      "Epoch 76/80\n",
      "40000/40000 [==============================] - 1s 28us/step - loss: 1.4482 - acc: 0.5292 - val_loss: 1.5578 - val_acc: 0.4951\n",
      "Epoch 77/80\n",
      "40000/40000 [==============================] - 1s 27us/step - loss: 1.4667 - acc: 0.5179 - val_loss: 1.5787 - val_acc: 0.4910\n",
      "Epoch 78/80\n",
      "40000/40000 [==============================] - 1s 30us/step - loss: 1.4597 - acc: 0.5231 - val_loss: 1.5587 - val_acc: 0.4950\n",
      "Epoch 79/80\n",
      "40000/40000 [==============================] - 1s 29us/step - loss: 1.4644 - acc: 0.5205 - val_loss: 1.5493 - val_acc: 0.5018\n",
      "Epoch 80/80\n",
      "40000/40000 [==============================] - 1s 29us/step - loss: 1.4528 - acc: 0.5259 - val_loss: 1.5291 - val_acc: 0.5083\n",
      "10000/10000 [==============================] - 0s 11us/step\n",
      "\n",
      "Test accuracy: 51.0%\n",
      "Loss: 1.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(history):\n",
    "\t# list all data in history\n",
    "\tprint(history.history.keys())\n",
    "\t# summarize history for accuracy\n",
    "\tplt.plot(history.history['acc'])\n",
    "\tplt.plot(history.history['val_acc'])\n",
    "\tplt.title('model accuracy')\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'test'], loc='upper left')\n",
    "\tplt.show()\n",
    "\t# summarize history for loss\n",
    "\tplt.plot(history.history['loss'])\n",
    "\tplt.plot(history.history['val_loss'])\n",
    "\tplt.title('model loss')\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'test'], loc='upper left')\n",
    "\tplt.show()\n",
    "\n",
    "# load dataset\n",
    "# 50k train + 10k test\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# train on smaller data set\n",
    "#(x_train, y_train), (x_test, y_test) = (x_train[:5000], y_train[:5000]), (x_test[:1000], y_test[:1000])\n",
    "\n",
    "# display number of labels\n",
    "num_samples = len(x_train)\n",
    "num_labels = len(np.unique(y_train))\n",
    "\n",
    "# one-hot vector\n",
    "# [airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck]\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# image dimensions\n",
    "image_size_x, image_size_y, dim = x_train.shape[1:]\n",
    "input_size = image_size_x * image_size_y * dim\n",
    "\n",
    "# resize and normalize\n",
    "x_train = np.reshape(x_train, [-1, input_size])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = np.reshape(x_test, [-1, input_size])\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# parameters\n",
    "batch_size = 128\n",
    "epochs = 80\n",
    "hidden_units = 100\n",
    "dropout = 0.1\n",
    "\n",
    "# model is a 3-layer MLP \n",
    "model = Sequential()\n",
    "\n",
    "# 1st hidden layer\n",
    "model.add(Dense(hidden_units, input_dim=input_size,\n",
    "\t\t\t\tkernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(dropout))\n",
    "# 2nd hidden layer\n",
    "model.add(Dense(hidden_units,\n",
    "\t\t\t\tkernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(dropout))\n",
    "# output layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "# plot_model(model, to_file='model-mlp.png')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# train the network\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "\t\t\t\t\tvalidation_split=0.2)\n",
    "\n",
    "# validate the model on test dataset to determine generalization\n",
    "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n",
    "print(\"Loss: %.1f\" % (loss))\n",
    "\n",
    "# plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
